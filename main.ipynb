{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'PoincareMaps'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/PoincareMaps.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scanpy fastdtw stochman torchplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prarabdha\\Downloads\\rvae-master\\rvae-master\\PoincareMaps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scanpy\n",
      "  Downloading scanpy-1.9.3-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 646.0 kB/s eta 0:00:00\n",
      "Collecting fastdtw\n",
      "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 kB 2.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting stochman\n",
      "  Downloading stochman-0.3.0.tar.gz (33 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting torchplot\n",
      "  Downloading torchplot-0.2.0.tar.gz (9.9 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting patsy\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.8/233.8 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting session-info\n",
      "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scipy>=1.4 in c:\\python310\\lib\\site-packages (from scanpy) (1.7.3)\n",
      "Requirement already satisfied: h5py>=3 in c:\\python310\\lib\\site-packages (from scanpy) (3.6.0)\n",
      "Requirement already satisfied: networkx>=2.3 in c:\\python310\\lib\\site-packages (from scanpy) (2.8.8)\n",
      "Requirement already satisfied: seaborn in c:\\python310\\lib\\site-packages (from scanpy) (0.12.0)\n",
      "Collecting umap-learn>=0.3.10\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "     ---------------------------------------- 88.2/88.2 kB 1.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting statsmodels>=0.10.0rc2\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\python310\\lib\\site-packages (from scanpy) (1.5.3)\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from scanpy) (21.3)\n",
      "Collecting anndata>=0.7.4\n",
      "  Downloading anndata-0.9.2-py3-none-any.whl (104 kB)\n",
      "     -------------------------------------- 104.2/104.2 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from scanpy) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\python310\\lib\\site-packages (from scanpy) (1.0.2)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from scanpy) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.41.0 in c:\\python310\\lib\\site-packages (from scanpy) (0.56.4)\n",
      "Requirement already satisfied: matplotlib>=3.4 in c:\\python310\\lib\\site-packages (from scanpy) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\python310\\lib\\site-packages (from scanpy) (1.24.1)\n",
      "Requirement already satisfied: torch>=1.7 in c:\\python310\\lib\\site-packages (from stochman) (1.13.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (4.29.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (0.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from numba>=0.41.0->scanpy) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\python310\\lib\\site-packages (from numba>=0.41.0->scanpy) (0.39.1)\n",
      "Collecting numpy>=1.17.0\n",
      "  Using cached numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas>=1.0->scanpy) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n",
      "  Using cached numpy-1.22.4-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from patsy->scanpy) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python310\\lib\\site-packages (from torch>=1.7->stochman) (4.5.0)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 2.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting stdlib_list\n",
      "  Downloading stdlib_list-0.9.0-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.6/75.6 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm->scanpy) (0.4.4)\n",
      "Building wheels for collected packages: fastdtw, stochman, torchplot, umap-learn, session-info, pynndescent\n",
      "  Building wheel for fastdtw (setup.py): started\n",
      "  Building wheel for fastdtw (setup.py): finished with status 'done'\n",
      "  Created wheel for fastdtw: filename=fastdtw-0.3.4-py3-none-any.whl size=3566 sha256=2b40379bfd6fdb057bbdb4d591ef37517a514190a720412d28d3023ec7e2cb69\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\73\\c8\\f7\\c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
      "  Building wheel for stochman (pyproject.toml): started\n",
      "  Building wheel for stochman (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for stochman: filename=stochman-0.3.0-py3-none-any.whl size=33140 sha256=7f39bd85a54dd8fea0c29e364dfa6b4023a4897dcace2eafe8ab7be180ee481f\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\89\\0e\\02\\662105abf91f6070faccb22abe65284c28a30fd2f64be10ea5\n",
      "  Building wheel for torchplot (pyproject.toml): started\n",
      "  Building wheel for torchplot (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for torchplot: filename=torchplot-0.2.0-py3-none-any.whl size=8337 sha256=5426d8e1f7ed3d6600c548dd29dcc1b9b0ffcd0055bc7b1ace428470a81ca070\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\31\\2b\\c1\\4ca4498b33f423af088f7c9a6fd47ba11505d9a3b5585073c4\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82814 sha256=e4b8228381d418e0e73e7c30227ae8b02ec9d26813f2afc080a6c02a81174b7d\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\a0\\e8\\c6\\a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
      "  Building wheel for session-info (setup.py): started\n",
      "  Building wheel for session-info (setup.py): finished with status 'done'\n",
      "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8037 sha256=2e47329a6aa4713249089b92341f0d99f8c25e879e77c878f95f8dfb752243ea\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\6a\\aa\\b9\\eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=c5a75e914b3e2aed572e13da4e2e6ad6efe3efb6b7b4abafb18084ba3795ffc6\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\4a\\38\\5d\\f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
      "Successfully built fastdtw stochman torchplot umap-learn session-info pynndescent\n",
      "Installing collected packages: stdlib_list, numpy, natsort, session-info, patsy, fastdtw, torchplot, stochman, statsmodels, anndata, pynndescent, umap-learn, scanpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Python310\\\\Lib\\\\site-packages\\\\scanpy\\\\_metadata.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\\\python310\\\\lib\\\\site-packages\\\\numpy-1.24.1.dist-info\\\\METADATA'\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "    WARNING: No metadata found in c:\\python310\\lib\\site-packages\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "argilla 1.2.1 requires httpx<0.24,>=0.15, but you have httpx 0.24.1 which is incompatible.\n",
      "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 2.0.7 which is incompatible.\n",
      "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.10.0 which is incompatible.\n",
      "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.10.0 which is incompatible.\n",
      "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.10.0 which is incompatible.\n",
      "splade 2.1 requires transformers==4.18.0, but you have transformers 4.29.2 which is incompatible.\n",
      "giskard 1.7.2 requires importlib_metadata<5.0.0,>=4.11.4, but you have importlib-metadata 6.0.1 which is incompatible.\n",
      "giskard 1.7.2 requires numpy<1.22.0,>=1.21.6, but you have numpy 1.22.4 which is incompatible.\n",
      "chromadb 0.3.25 requires tokenizers>=0.13.2, but you have tokenizers 0.12.1 which is incompatible.\n",
      "apache-beam 2.41.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\n",
      "apache-beam 2.41.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 11.0.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scanpy\n",
      "  Using cached scanpy-1.9.3-py3-none-any.whl (2.0 MB)\n",
      "Collecting fastdtw\n",
      "  Using cached fastdtw-0.3.4-py3-none-any.whl\n",
      "Collecting stochman\n",
      "  Using cached stochman-0.3.0-py3-none-any.whl\n",
      "Collecting torchplot\n",
      "  Using cached torchplot-0.2.0-py3-none-any.whl\n",
      "Collecting statsmodels>=0.10.0rc2\n",
      "  Using cached statsmodels-0.14.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\python310\\lib\\site-packages (from scanpy) (1.24.1)\n",
      "Requirement already satisfied: matplotlib>=3.4 in c:\\python310\\lib\\site-packages (from scanpy) (3.5.3)\n",
      "Requirement already satisfied: numba>=0.41.0 in c:\\python310\\lib\\site-packages (from scanpy) (0.56.4)\n",
      "Requirement already satisfied: scipy>=1.4 in c:\\python310\\lib\\site-packages (from scanpy) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\python310\\lib\\site-packages (from scanpy) (1.0.2)\n",
      "Requirement already satisfied: networkx>=2.3 in c:\\python310\\lib\\site-packages (from scanpy) (2.8.8)\n",
      "Collecting session-info\n",
      "  Using cached session_info-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: seaborn in c:\\python310\\lib\\site-packages (from scanpy) (0.12.0)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\python310\\lib\\site-packages (from scanpy) (1.5.3)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from scanpy) (4.65.0)\n",
      "Collecting patsy\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from scanpy) (21.3)\n",
      "Requirement already satisfied: h5py>=3 in c:\\python310\\lib\\site-packages (from scanpy) (3.6.0)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from scanpy) (1.1.0)\n",
      "Collecting umap-learn>=0.3.10\n",
      "  Using cached umap_learn-0.5.3-py3-none-any.whl\n",
      "Collecting anndata>=0.7.4\n",
      "  Using cached anndata-0.9.2-py3-none-any.whl (104 kB)\n",
      "Collecting natsort\n",
      "  Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: torch>=1.7 in c:\\python310\\lib\\site-packages (from stochman) (1.13.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (4.29.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python310\\lib\\site-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n",
      "Collecting numpy>=1.17.0\n",
      "  Using cached numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\python310\\lib\\site-packages (from numba>=0.41.0->scanpy) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from numba>=0.41.0->scanpy) (65.6.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas>=1.0->scanpy) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n",
      "  Using cached numpy-1.22.4-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from patsy->scanpy) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python310\\lib\\site-packages (from torch>=1.7->stochman) (4.5.0)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting stdlib-list\n",
      "  Using cached stdlib_list-0.9.0-py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm->scanpy) (0.4.4)\n",
      "Building wheels for collected packages: pynndescent\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=25fe024dde173a73aad7cc027d37117894efad1d58183aaa4bf987b5482ed733\n",
      "  Stored in directory: c:\\users\\prarabdha\\appdata\\local\\pip\\cache\\wheels\\4a\\38\\5d\\f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
      "Successfully built pynndescent\n",
      "Installing collected packages: stdlib-list, numpy, natsort, session-info, patsy, fastdtw, torchplot, stochman, statsmodels, anndata, pynndescent, umap-learn, scanpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Can't uninstall 'numpy'. No files were found to uninstall.\n",
      "Successfully installed anndata-0.9.2 fastdtw-0.3.4 natsort-8.4.0 numpy-1.22.4 patsy-0.5.3 pynndescent-0.5.10 scanpy-1.9.3 session-info-1.0.0 statsmodels-0.14.0 stdlib-list-0.9.0 stochman-0.3.0 torchplot-0.2.0 umap-learn-0.5.3\n"
     ]
    }
   ],
   "source": [
    "%cd PoincareMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from main import *\n",
    "from poincare_maps import *\n",
    "# from PoincareMaps.main import *\n",
    "\n",
    "%matplotlib inline\n",
    "# from PoincareMaps.poincare_maps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fullpath = './datasets/Paul'\n",
    "features, labels = prepare_data(dataset_fullpath,\n",
    "                                with_labels=True,\n",
    "                                normalize=True,\n",
    "                                n_pca=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7070, -0.1914, -0.2720,  ..., -0.4816, -0.4488, -0.2217],\n",
       "         [ 0.3422, -0.1914, -0.2720,  ...,  1.6369, -0.4488, -0.2217],\n",
       "         [ 0.1302, -0.1914, -0.2720,  ...,  1.2589,  0.6859, -0.2217],\n",
       "         ...,\n",
       "         [-0.7070, -0.1914,  5.6759,  ..., -0.4816, -0.4488, -0.2217],\n",
       "         [ 2.1656, -0.1914,  1.4426,  ..., -0.4816, -0.4488, -0.2217],\n",
       "         [-0.0295, -0.1914, -0.2720,  ..., -0.4816, -0.4488,  1.3923]],\n",
       "        dtype=torch.float64),\n",
       " array(['7MEP', '15Mo', '3Ery', ..., '7MEP', '15Mo', '3Ery'], dtype='<U7'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prarabdha\\Downloads\\rvae-master\\rvae-master\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2730, 1000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from rvae.geoml import nnj\n",
    "from rvae.variational_inference.train import train_rvae, test_rvae, train_vae, test_vae\n",
    "from rvae.utils.data_utils import get_mnist_loaders, get_fmnist_loaders, get_kmnist_loaders\n",
    "from rvae.models.vae import RVAE, VAE\n",
    "from rvae.utils.save_utils import save_model, load_model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self,features):\n",
    "        # self.dataset = \"mnist\"\n",
    "\n",
    "        features = features.type(torch.float32)\n",
    "        self.train_loader = DataLoader(features, batch_size=100, shuffle=True)\n",
    "        self.test_loader = DataLoader(features, batch_size=100, shuffle=True)\n",
    "        in_dim = 1000\n",
    "\n",
    "        if not os.path.exists(\"./data/\"):\n",
    "            os.makedirs(\"./data/\")\n",
    "        # if self.dataset == \"mnist\":\n",
    "        #     self.train_loader, self.test_loader = get_mnist_loaders(\"./data/\", 100)\n",
    "        #     in_dim = 784\n",
    "        # elif self.dataset == \"fmnist\":\n",
    "        #     self.train_loader, self.test_loader = get_fmnist_loaders(\"./data/\", 100)\n",
    "        #     in_dim = 784\n",
    "        # elif self.dataset == \"kmnist\":\n",
    "        #     self.train_loader, self.test_loader = get_kmnist_loaders(\"./data/\", 100)\n",
    "        #     in_dim = 784\n",
    "\n",
    "        self.rvae_save_dir = os.path.join(\"./saved_models/\", \"RVAE/\")\n",
    "        self.vae_save_dir = os.path.join(\"./saved_models/\", \"VAE/\")\n",
    "        if not os.path.exists(self.rvae_save_dir):\n",
    "            os.makedirs(self.rvae_save_dir)\n",
    "        if not os.path.exists(self.vae_save_dir):\n",
    "            os.makedirs(self.vae_save_dir)\n",
    "\n",
    "        if not os.path.exists(\"./results/\"):\n",
    "            os.makedirs(\"./results/\")\n",
    "            # create graph directory\n",
    "            os.makedirs(\"./results/\" + \"graphs/\")\n",
    "            # create model samples directory\n",
    "            os.makedirs(\"./results/\" + \"samples/\")\n",
    "\n",
    "        # if args.seed is not None:\n",
    "        #     assert(type(args.seed) == int)\n",
    "        #     torch.manual_seed(args.seed)\n",
    "        #     np.random.seed(args.seed)\n",
    "\n",
    "        self.model = RVAE(in_dim, 2, 64, [512,256,128],\n",
    "                              [128,256,512], nnj.Softplus, nnj.Sigmoid, 0.01, 1e-9)\n",
    "        # if args.model.lower() == \"rvae\":\n",
    "        #     self.model = RVAE(in_dim, args.latent_dim, args.num_centers, args.enc_layers,\n",
    "        #                       args.dec_layers, nnj.Softplus, nnj.Sigmoid, args.rbf_beta, args.rec_b)\n",
    "        # elif args.model.lower() == \"vae\":\n",
    "        #     self.model = VAE(in_dim, args.latent_dim, args.num_centers, args.num_components,\n",
    "        #                      args.enc_layers, args.dec_layers, nnj.Softplus, nnj.Sigmoid,\n",
    "        #                      args.rbf_beta, args.rec_b)\n",
    "\n",
    "        self.batch_size = 100\n",
    "        self.mu_epochs = 100\n",
    "        self.sigma_epochs = 100\n",
    "        self.warmup_learning_rate = 1e-3\n",
    "        self.sigma_learning_rate = 1e-3\n",
    "        self.log_invl = 100\n",
    "        self.save_invl = 25\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def train(self):\n",
    "        self.model = self.model.to(self.device)\n",
    "        # ================= RVAE =================\n",
    "        if isinstance(self.model, RVAE):\n",
    "            warmup_optimizer = torch.optim.Adam(\n",
    "                chain(\n",
    "                    self.model.encoder.parameters(),\n",
    "                    self.model.q_mu.parameters(),\n",
    "                    self.model.q_t.parameters(),\n",
    "                    self.model.p_mu.parameters()),\n",
    "                lr=self.warmup_learning_rate\n",
    "            )\n",
    "            sigma_optimizer = torch.optim.Adam(\n",
    "                chain(\n",
    "                    self.model.p_sigma.parameters(),\n",
    "                    [self.model.pr_means, self.model.pr_t]),\n",
    "                lr=self.sigma_learning_rate\n",
    "            )\n",
    "\n",
    "            # encoder/decoder mean optimization\n",
    "            for epoch in range(1, self.mu_epochs + 1):\n",
    "                loss, _, _ = train_rvae(epoch, self.train_loader, self.batch_size, self.model,\n",
    "                                        warmup_optimizer, self.log_invl, self.device)\n",
    "                print(\"\\tEpoch: {} (warmup phase), negative ELBO: {:.3f}\".format(epoch, loss))\n",
    "\n",
    "            # warmup checkpoint\n",
    "            savepath = os.path.join(self.rvae_save_dir, \"Paul_warmup\")\n",
    "            save_model(self.model, sigma_optimizer, 0, None, savepath)\n",
    "\n",
    "            self.model.switch = False\n",
    "            self.model._update_latent_codes(self.train_loader)\n",
    "            self.model._update_RBF_centers(beta=0.01)\n",
    "            self.model._mean_warmup = False\n",
    "            self.model._initialize_prior_means()\n",
    "\n",
    "            # decoder sigma/prior parameters optimization\n",
    "            for epoch in range(1, self.sigma_epochs + 1):\n",
    "                loss, _, _ = train_rvae(epoch, self.train_loader, self.batch_size, self.model,\n",
    "                                        sigma_optimizer, self.log_invl, self.device)\n",
    "                print(\"\\tEpoch: {} (sigma optimization), negative ELBO: {:.3f}\".format(epoch, loss))\n",
    "\n",
    "            savepath = os.path.join(self.rvae_save_dir,\n",
    "                                    \"Paul_epoch\"+str(epoch)+\"ckpt\")\n",
    "            save_model(self.model, sigma_optimizer, epoch, loss, savepath)\n",
    "\n",
    "        # ================= VAE =================\n",
    "        else:\n",
    "            warmup_optimizer = torch.optim.Adam(\n",
    "                chain(self.model.encoder.parameters(),\n",
    "                      self.model.q_mu.parameters(),\n",
    "                      self.model.q_var.parameters(),\n",
    "                      self.model.decoder.parameters(),\n",
    "                      self.model.p_mu.parameters()),\n",
    "                      lr=self.warmup_learning_rate\n",
    "            )\n",
    "\n",
    "            if self.model.num_components > 1:\n",
    "                sigma_optimizer = torch.optim.Adam(\n",
    "                    chain(self.model.p_sigma.parameters(), self.model.means.parameters()),\n",
    "                    lr=self.sigma_learning_rate\n",
    "                )\n",
    "            else:\n",
    "                sigma_optimizer = torch.optim.Adam(\n",
    "                    self.model.p_sigma.parameters(),\n",
    "                    lr=self.sigma_learning_rate\n",
    "                )\n",
    "\n",
    "            # encoder/decoder mean optimization\n",
    "            for epoch in range(1, self.mu_epochs + 1):\n",
    "                loss, _, _ = train_vae(epoch, self.mu_epochs, self.train_loader, self.batch_size, self.model,\n",
    "                                       warmup_optimizer, self.log_invl, self.device)\n",
    "                print(\"\\tEpoch: {} (warmup phase), negative ELBO: {:.3f}\".format(epoch, loss))\n",
    "\n",
    "            # warmup checkpoint\n",
    "            savepath = os.path.join(self.rvae_save_dir, \"Paul_warmup\")\n",
    "            save_model(self.model, sigma_optimizer, 0, None, savepath)\n",
    "\n",
    "            self.model.switch = False\n",
    "            self.model._update_latent_codes(self.train_loader)\n",
    "            self.model._update_RBF_centers(beta=0.01)\n",
    "\n",
    "            for epoch in range(1, self.sigma_epochs + 1):\n",
    "                loss, _, _ = train_vae(epoch, 1, self.train_loader, self.batch_size, self.model,\n",
    "                                       sigma_optimizer, self.log_invl, self.device)\n",
    "                print(\"\\tEpoch: {} (sigma optimization), negative ELBO: {:.3f}\".format(epoch, loss))\n",
    "\n",
    "                if epoch % self.save_invl == 0:\n",
    "                    savepath = os.path.join(self.vae_save_dir,\n",
    "                                            self.dataset+\"_K\"+str(self.model.num_components)+\"epoch\"+str(epoch)+\".ckpt\")\n",
    "                    save_model(self.model, sigma_optimizer, epoch, loss, savepath)\n",
    "\n",
    "    def eval(self, pretrained_path=None):\n",
    "        # load checkpoint\n",
    "        if pretrained_path is not None:\n",
    "            placeholder_optimizer = torch.optim.Adam(\n",
    "                self.model.p_sigma.parameters(),\n",
    "                lr=1e-3\n",
    "            )\n",
    "            load_model(pretrained_path, self.model, placeholder_optimizer)\n",
    "\n",
    "        if isinstance(self.model, RVAE):\n",
    "            loss, log_cond, KL = test_rvae(self.test_loader, self.batch_size, self.model, self.device)\n",
    "        else:\n",
    "            loss, log_cond, KL = test_vae(self.test_loader, self.batch_size, self.model, self.device)\n",
    "\n",
    "        print(\"Test set negative ELBO: {:.3f}, negative conditional: {:.3f}, KL: {:.3f}\".format(loss, log_cond, KL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch: 0, loss: 1522.985, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1520.560, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1432.424, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1441.876, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1453.704, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1422.975, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1412.837, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1403.263, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1430.549, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1414.766, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1388.730, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1429.361, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1404.777, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1411.184, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1393.420, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1427.881, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1411.333, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1424.740, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1444.121, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1408.823, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1499.888, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1419.800, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1434.715, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1405.098, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1418.209, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1416.557, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1406.595, KL: 0.000\n",
      "Epoch: 1, batch: 0, loss: 1477.090, KL: 0.000\n",
      "\tEpoch: 1 (warmup phase), negative ELBO: 1484.380\n",
      "Epoch: 2, batch: 0, loss: 1412.840, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1436.358, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1371.595, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1351.964, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1403.827, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1444.591, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1419.271, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1403.828, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1481.054, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1438.265, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1438.450, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1422.301, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1383.361, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1422.311, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1437.397, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1510.761, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1379.882, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1378.201, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1396.505, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1389.688, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1413.145, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1481.527, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1423.367, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1408.789, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1438.475, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1396.760, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1440.470, KL: 0.000\n",
      "Epoch: 2, batch: 0, loss: 1373.452, KL: 0.000\n",
      "\tEpoch: 2 (warmup phase), negative ELBO: 1470.313\n",
      "Epoch: 3, batch: 0, loss: 1433.081, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1409.411, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1410.136, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1451.445, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1450.338, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1428.845, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1401.810, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1398.854, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1494.915, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1439.499, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1435.986, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1436.082, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1397.907, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1372.445, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1447.438, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1405.349, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1398.420, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1424.321, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1419.633, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1422.287, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1400.420, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1408.264, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1379.216, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1421.126, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1451.870, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1393.344, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1396.224, KL: 0.000\n",
      "Epoch: 3, batch: 0, loss: 1361.186, KL: 0.000\n",
      "\tEpoch: 3 (warmup phase), negative ELBO: 1469.994\n",
      "Epoch: 4, batch: 0, loss: 1415.874, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1456.699, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1418.333, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1428.777, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1442.516, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1428.002, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1414.083, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1406.462, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1445.927, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1402.195, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1399.075, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1432.020, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1432.654, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1411.537, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1451.668, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1376.139, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1406.116, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1396.509, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1384.774, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1449.565, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1396.269, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1405.765, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1419.716, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1421.055, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1419.507, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1432.571, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1428.808, KL: 0.000\n",
      "Epoch: 4, batch: 0, loss: 1381.355, KL: 0.000\n",
      "\tEpoch: 4 (warmup phase), negative ELBO: 1470.517\n",
      "Epoch: 5, batch: 0, loss: 1433.130, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1393.384, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1454.309, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1497.302, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1407.856, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1399.792, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1494.594, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1407.896, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1410.881, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1388.031, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1450.297, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1399.381, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1419.912, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1420.384, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1385.823, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1443.543, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1392.982, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1384.842, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1407.267, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1401.973, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1459.548, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1435.804, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1432.140, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1392.031, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1402.519, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1393.966, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1408.912, KL: 0.000\n",
      "Epoch: 5, batch: 0, loss: 1395.082, KL: 0.000\n",
      "\tEpoch: 5 (warmup phase), negative ELBO: 1470.873\n",
      "Epoch: 6, batch: 0, loss: 1392.014, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1400.345, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1435.213, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1407.014, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1394.115, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1460.998, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1436.653, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1438.694, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1463.114, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1369.047, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1420.469, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1385.557, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1437.592, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1417.141, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1400.860, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1394.487, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1416.428, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1545.569, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1379.016, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1379.550, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1402.206, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1379.437, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1451.098, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1395.599, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1440.950, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1435.373, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1412.007, KL: 0.000\n",
      "Epoch: 6, batch: 0, loss: 1488.248, KL: 0.000\n",
      "\tEpoch: 6 (warmup phase), negative ELBO: 1473.289\n",
      "Epoch: 7, batch: 0, loss: 1408.684, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1406.987, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1426.032, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1441.090, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1417.932, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1437.151, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1432.358, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1449.419, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1363.546, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1415.306, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1378.775, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1378.144, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1377.875, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1488.261, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1402.420, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1405.115, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1466.749, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1402.120, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1438.616, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1395.489, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1455.372, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1414.310, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1394.634, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1404.761, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1395.082, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1454.583, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1448.322, KL: 0.000\n",
      "Epoch: 7, batch: 0, loss: 1459.627, KL: 0.000\n",
      "\tEpoch: 7 (warmup phase), negative ELBO: 1472.547\n",
      "Epoch: 8, batch: 0, loss: 1363.681, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1409.774, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1395.045, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1454.343, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1443.840, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1435.003, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1409.608, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1392.776, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1470.452, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1390.315, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1503.841, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1408.812, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1446.020, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1447.301, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1406.487, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1445.986, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1401.254, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1423.929, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1383.255, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1452.303, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1403.553, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1381.592, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1403.707, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1411.043, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1350.729, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1449.007, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1430.308, KL: 0.000\n",
      "Epoch: 8, batch: 0, loss: 1410.184, KL: 0.000\n",
      "\tEpoch: 8 (warmup phase), negative ELBO: 1471.265\n",
      "Epoch: 9, batch: 0, loss: 1345.246, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1369.826, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1439.172, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1437.918, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1411.029, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1479.228, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1420.034, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1386.862, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1440.215, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1400.787, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1376.222, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1446.611, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1414.702, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1492.015, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1396.697, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1412.591, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1447.277, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1373.278, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1432.347, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1399.380, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1459.987, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1428.619, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1414.395, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1403.695, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1472.918, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1421.115, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1408.912, KL: 0.000\n",
      "Epoch: 9, batch: 0, loss: 1353.146, KL: 0.000\n",
      "\tEpoch: 9 (warmup phase), negative ELBO: 1469.786\n",
      "Epoch: 10, batch: 0, loss: 1384.384, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1445.407, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1358.349, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1415.502, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1457.016, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1470.294, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1419.377, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1393.280, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1422.505, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1460.944, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1406.227, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1385.219, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1415.284, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1492.857, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1422.362, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1406.125, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1409.726, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1411.761, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1381.173, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1402.233, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1398.850, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1424.985, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1420.571, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1453.931, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1378.802, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1448.021, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1444.007, KL: 0.000\n",
      "Epoch: 10, batch: 0, loss: 1359.438, KL: 0.000\n",
      "\tEpoch: 10 (warmup phase), negative ELBO: 1469.949\n",
      "Epoch: 11, batch: 0, loss: 1408.489, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1441.825, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1413.334, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1457.628, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1456.482, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1365.479, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1420.079, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1426.170, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1390.354, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1418.923, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1425.048, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1402.673, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1460.542, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1424.865, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1435.440, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1409.116, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1380.192, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1366.171, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1443.017, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1426.870, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1374.836, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1397.759, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1411.855, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1447.503, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1463.278, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1450.857, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1413.806, KL: 0.000\n",
      "Epoch: 11, batch: 0, loss: 1348.103, KL: 0.000\n",
      "\tEpoch: 11 (warmup phase), negative ELBO: 1469.655\n",
      "Epoch: 12, batch: 0, loss: 1389.974, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1450.366, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1461.370, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1388.805, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1433.313, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1422.113, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1376.089, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1434.618, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1444.522, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1437.275, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1403.696, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1425.995, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1402.698, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1428.407, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1363.434, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1456.632, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1425.716, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1394.035, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1413.953, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1420.170, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1454.308, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1413.982, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1421.799, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1418.430, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1392.108, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1415.432, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1428.422, KL: 0.000\n",
      "Epoch: 12, batch: 0, loss: 1397.870, KL: 0.000\n",
      "\tEpoch: 12 (warmup phase), negative ELBO: 1470.946\n",
      "Epoch: 13, batch: 0, loss: 1450.695, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1425.279, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1453.840, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1434.149, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1368.173, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1437.199, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1353.044, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1495.864, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1356.873, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1451.857, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1448.865, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1458.290, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1484.168, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1399.281, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1441.188, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1408.343, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1441.593, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1384.149, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1400.918, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1408.620, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1429.297, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1413.192, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1402.029, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1394.632, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1397.656, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1357.776, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1412.099, KL: 0.000\n",
      "Epoch: 13, batch: 0, loss: 1426.506, KL: 0.000\n",
      "\tEpoch: 13 (warmup phase), negative ELBO: 1471.688\n",
      "Epoch: 14, batch: 0, loss: 1414.089, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1428.086, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1425.888, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1457.480, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1406.281, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1422.201, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1433.282, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1373.642, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1397.637, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1439.218, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1395.525, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1383.847, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1363.965, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1426.924, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1418.301, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1406.888, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1362.437, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1370.371, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1489.682, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1446.788, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1448.787, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1432.217, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1411.482, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1435.674, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1449.910, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1413.536, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1451.845, KL: 0.000\n",
      "Epoch: 14, batch: 0, loss: 1436.797, KL: 0.000\n",
      "\tEpoch: 14 (warmup phase), negative ELBO: 1471.955\n",
      "Epoch: 15, batch: 0, loss: 1394.922, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1406.085, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1427.499, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1421.842, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1415.032, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1445.151, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1407.185, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1462.255, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1452.651, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1430.383, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1398.540, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1413.844, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1434.695, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1403.086, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1392.440, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1391.570, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1470.300, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1417.347, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1395.810, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1440.732, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1358.292, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1487.187, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1394.560, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1487.271, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1411.387, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1416.211, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1363.275, KL: 0.000\n",
      "Epoch: 15, batch: 0, loss: 1324.898, KL: 0.000\n",
      "\tEpoch: 15 (warmup phase), negative ELBO: 1469.054\n",
      "Epoch: 16, batch: 0, loss: 1510.087, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1427.212, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1432.423, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1436.358, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1405.840, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1440.375, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1415.978, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1392.920, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1492.883, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1418.750, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1453.042, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1424.724, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1391.405, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1452.785, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1344.688, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1385.531, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1339.919, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1371.076, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1405.911, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1379.619, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1454.869, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1461.269, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1399.373, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1407.357, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1400.189, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1461.324, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1422.641, KL: 0.000\n",
      "Epoch: 16, batch: 0, loss: 1361.580, KL: 0.000\n",
      "\tEpoch: 16 (warmup phase), negative ELBO: 1470.005\n",
      "Epoch: 17, batch: 0, loss: 1393.446, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1399.743, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1403.955, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1361.027, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1423.733, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1454.892, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1407.623, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1462.666, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1472.716, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1382.800, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1411.977, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1432.340, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1436.682, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1450.599, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1442.375, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1401.074, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1409.222, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1404.412, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1404.729, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1417.170, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1401.172, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1390.829, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1482.683, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1380.802, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1407.976, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1419.268, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1445.473, KL: 0.000\n",
      "Epoch: 17, batch: 0, loss: 1452.127, KL: 0.000\n",
      "\tEpoch: 17 (warmup phase), negative ELBO: 1472.352\n",
      "Epoch: 18, batch: 0, loss: 1378.503, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1444.194, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1381.584, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1457.691, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1419.962, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1401.977, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1374.896, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1434.069, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1455.109, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1388.170, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1467.248, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1435.236, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1387.691, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1381.108, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1448.112, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1379.891, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1458.093, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1402.567, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1423.584, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1426.890, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1399.372, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1435.029, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1397.875, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1451.976, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1406.788, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1407.839, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1481.213, KL: 0.000\n",
      "Epoch: 18, batch: 0, loss: 1367.850, KL: 0.000\n",
      "\tEpoch: 18 (warmup phase), negative ELBO: 1470.167\n",
      "Epoch: 19, batch: 0, loss: 1402.115, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1389.231, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1405.931, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1403.879, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1455.357, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1411.677, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1435.945, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1404.472, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1430.998, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1394.659, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1417.051, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1393.387, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1369.969, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1458.902, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1388.606, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1410.078, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1499.075, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1397.025, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1411.824, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1393.154, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1498.494, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1424.594, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1423.643, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1411.528, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1423.670, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1433.284, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1436.443, KL: 0.000\n",
      "Epoch: 19, batch: 0, loss: 1373.429, KL: 0.000\n",
      "\tEpoch: 19 (warmup phase), negative ELBO: 1470.312\n",
      "Epoch: 20, batch: 0, loss: 1464.054, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1423.764, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1353.887, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1427.417, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1411.900, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1396.471, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1436.142, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1412.669, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1449.625, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1409.564, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1445.066, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1419.896, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1417.818, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1418.306, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1380.422, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1465.000, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1440.400, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1457.012, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1394.658, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1376.519, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1438.627, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1461.644, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1441.310, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1388.967, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1408.695, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1390.112, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1382.732, KL: 0.000\n",
      "Epoch: 20, batch: 0, loss: 1414.489, KL: 0.000\n",
      "\tEpoch: 20 (warmup phase), negative ELBO: 1471.376\n",
      "Epoch: 21, batch: 0, loss: 1398.285, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1389.560, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1435.188, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1468.144, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1385.713, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1429.354, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1424.949, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1420.788, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1416.295, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1485.564, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1386.164, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1419.262, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1412.934, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1446.921, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1454.111, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1461.926, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1373.720, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1395.061, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1389.759, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1373.346, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1426.675, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1414.536, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1421.909, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1463.232, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1423.372, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1419.299, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1367.880, KL: 0.000\n",
      "Epoch: 21, batch: 0, loss: 1443.589, KL: 0.000\n",
      "\tEpoch: 21 (warmup phase), negative ELBO: 1472.131\n",
      "Epoch: 22, batch: 0, loss: 1415.059, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1415.794, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1438.046, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1456.604, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1413.844, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1386.553, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1405.098, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1453.491, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1424.533, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1387.793, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1448.818, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1473.307, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1448.907, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1348.667, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1426.819, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1458.599, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1386.353, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1409.056, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1397.161, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1393.660, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1411.405, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1428.420, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1473.865, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1410.172, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1360.479, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1367.502, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1472.414, KL: 0.000\n",
      "Epoch: 22, batch: 0, loss: 1415.338, KL: 0.000\n",
      "\tEpoch: 22 (warmup phase), negative ELBO: 1471.398\n",
      "Epoch: 23, batch: 0, loss: 1415.831, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1404.662, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1418.729, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1403.012, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1433.221, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1476.022, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1380.496, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1495.816, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1456.029, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1417.093, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1393.648, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1377.661, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1416.927, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1443.143, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1395.588, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1386.875, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1415.705, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1437.445, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1402.177, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1405.903, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1474.336, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1400.451, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1408.640, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1368.039, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1440.754, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1447.019, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1419.161, KL: 0.000\n",
      "Epoch: 23, batch: 0, loss: 1342.131, KL: 0.000\n",
      "\tEpoch: 23 (warmup phase), negative ELBO: 1469.500\n",
      "Epoch: 24, batch: 0, loss: 1491.563, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1396.862, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1382.678, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1412.629, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1407.966, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1395.507, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1501.977, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1405.930, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1393.650, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1448.230, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1407.130, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1406.162, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1394.492, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1477.458, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1450.712, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1425.787, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1431.778, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1362.259, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1364.293, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1400.544, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1457.823, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1423.571, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1397.560, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1441.734, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1384.374, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1427.606, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1423.723, KL: 0.000\n",
      "Epoch: 24, batch: 0, loss: 1410.084, KL: 0.000\n",
      "\tEpoch: 24 (warmup phase), negative ELBO: 1471.262\n",
      "Epoch: 25, batch: 0, loss: 1399.951, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1403.029, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1429.940, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1431.113, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1369.471, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1437.483, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1447.604, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1443.507, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1441.653, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1434.073, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1386.409, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1412.550, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1378.378, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1393.202, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1320.013, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1442.014, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1409.874, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1414.832, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1412.794, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1499.031, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1415.647, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1428.390, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1481.228, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1403.343, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1424.463, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1428.769, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1420.777, KL: 0.000\n",
      "Epoch: 25, batch: 0, loss: 1424.945, KL: 0.000\n",
      "\tEpoch: 25 (warmup phase), negative ELBO: 1471.647\n",
      "Epoch: 26, batch: 0, loss: 1487.096, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1400.327, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1415.452, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1402.195, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1391.271, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1421.255, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1375.123, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1435.510, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1400.303, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1433.912, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1417.805, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1451.568, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1428.147, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1433.478, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1468.709, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1388.419, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1418.067, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1447.594, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1384.427, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1427.499, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1416.574, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1434.706, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1377.080, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1440.002, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1413.488, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1404.180, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1402.138, KL: 0.000\n",
      "Epoch: 26, batch: 0, loss: 1402.326, KL: 0.000\n",
      "\tEpoch: 26 (warmup phase), negative ELBO: 1471.061\n",
      "Epoch: 27, batch: 0, loss: 1471.098, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1382.050, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1432.244, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1389.577, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1435.360, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1351.123, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1416.995, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1440.727, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1421.098, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1379.793, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1438.845, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1379.182, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1424.516, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1421.805, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1410.737, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1436.773, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1420.104, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1387.363, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1405.426, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1472.886, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1412.043, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1442.098, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1415.782, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1391.207, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1450.354, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1405.572, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1454.051, KL: 0.000\n",
      "Epoch: 27, batch: 0, loss: 1494.044, KL: 0.000\n",
      "\tEpoch: 27 (warmup phase), negative ELBO: 1473.439\n",
      "Epoch: 28, batch: 0, loss: 1436.222, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1411.839, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1431.314, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1374.630, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1403.941, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1398.770, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1396.383, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1390.478, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1473.799, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1416.315, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1467.420, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1489.610, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1378.751, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1423.027, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1404.055, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1437.685, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1426.547, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1398.602, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1443.740, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1471.761, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1429.522, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1411.752, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1385.197, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1397.687, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1391.202, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1382.724, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1406.867, KL: 0.000\n",
      "Epoch: 28, batch: 0, loss: 1523.935, KL: 0.000\n",
      "\tEpoch: 28 (warmup phase), negative ELBO: 1474.214\n",
      "Epoch: 29, batch: 0, loss: 1444.412, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1361.334, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1462.725, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1404.671, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1423.409, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1440.730, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1433.731, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1434.354, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1408.154, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1414.255, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1376.773, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1394.651, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1416.752, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1399.907, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1403.449, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1441.391, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1422.908, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1410.121, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1396.649, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1487.194, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1442.472, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1381.896, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1420.023, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1461.541, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1413.379, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1434.748, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1408.394, KL: 0.000\n",
      "Epoch: 29, batch: 0, loss: 1323.339, KL: 0.000\n",
      "\tEpoch: 29 (warmup phase), negative ELBO: 1469.013\n",
      "Epoch: 30, batch: 0, loss: 1405.003, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1424.913, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1444.901, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1432.372, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1436.449, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1430.981, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1417.113, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1396.394, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1387.472, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1405.685, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1422.750, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1393.448, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1389.700, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1385.371, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1367.363, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1464.022, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1406.469, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1379.096, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1474.301, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1367.618, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1385.258, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1440.465, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1461.169, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1462.948, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1443.983, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1459.399, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1412.175, KL: 0.000\n",
      "Epoch: 30, batch: 0, loss: 1467.351, KL: 0.000\n",
      "\tEpoch: 30 (warmup phase), negative ELBO: 1472.747\n",
      "Epoch: 31, batch: 0, loss: 1398.332, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1433.223, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1450.875, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1427.910, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1435.107, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1463.473, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1401.062, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1409.922, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1370.887, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1406.910, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1465.238, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1383.971, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1403.236, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1371.893, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1408.469, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1432.024, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1442.625, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1409.142, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1404.574, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1433.508, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1434.219, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1380.827, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1439.526, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1426.168, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1402.751, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1404.783, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1461.637, KL: 0.000\n",
      "Epoch: 31, batch: 0, loss: 1449.099, KL: 0.000\n",
      "\tEpoch: 31 (warmup phase), negative ELBO: 1472.274\n",
      "Epoch: 32, batch: 0, loss: 1428.101, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1398.782, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1418.638, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1467.230, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1382.303, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1394.274, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1419.092, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1419.822, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1458.962, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1384.753, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1451.295, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1418.639, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1454.240, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1465.019, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1393.980, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1420.422, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1421.682, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1401.092, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1371.193, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1431.036, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1403.212, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1479.627, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1431.051, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1417.584, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1401.081, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1391.673, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1397.365, KL: 0.000\n",
      "Epoch: 32, batch: 0, loss: 1382.911, KL: 0.000\n",
      "\tEpoch: 32 (warmup phase), negative ELBO: 1470.558\n",
      "Epoch: 33, batch: 0, loss: 1437.629, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1402.502, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1411.527, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1420.657, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1386.469, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1431.891, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1419.801, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1419.051, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1369.160, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1458.062, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1352.757, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1465.046, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1429.489, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1466.225, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1425.209, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1423.111, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1446.815, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1423.702, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1421.679, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1422.657, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1362.872, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1435.086, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1401.294, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1397.885, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1443.494, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1399.117, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1439.547, KL: 0.000\n",
      "Epoch: 33, batch: 0, loss: 1414.289, KL: 0.000\n",
      "\tEpoch: 33 (warmup phase), negative ELBO: 1471.371\n",
      "Epoch: 34, batch: 0, loss: 1398.646, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1391.166, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1444.103, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1381.339, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1458.085, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1406.048, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1414.382, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1447.206, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1458.478, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1404.248, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1441.711, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1383.285, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1394.767, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1463.731, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1424.039, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1460.578, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1372.689, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1473.001, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1383.108, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1387.961, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1403.595, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1416.954, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1429.950, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1389.942, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1438.933, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1441.680, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1384.407, KL: 0.000\n",
      "Epoch: 34, batch: 0, loss: 1476.620, KL: 0.000\n",
      "\tEpoch: 34 (warmup phase), negative ELBO: 1472.987\n",
      "Epoch: 35, batch: 0, loss: 1484.546, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1419.896, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1396.553, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1456.371, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1422.245, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1439.964, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1403.737, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1426.151, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1387.827, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1451.804, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1483.297, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1391.974, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1424.666, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1391.143, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1440.999, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1403.379, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1382.049, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1406.851, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1383.941, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1395.058, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1385.301, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1403.662, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1426.783, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1384.788, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1408.062, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1410.794, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1449.381, KL: 0.000\n",
      "Epoch: 35, batch: 0, loss: 1585.992, KL: 0.000\n",
      "\tEpoch: 35 (warmup phase), negative ELBO: 1475.823\n",
      "Epoch: 36, batch: 0, loss: 1404.864, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1483.103, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1400.812, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1361.536, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1406.686, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1441.220, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1430.064, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1397.918, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1398.488, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1374.938, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1401.514, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1450.270, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1468.076, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1435.138, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1457.616, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1386.075, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1388.811, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1415.311, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1434.871, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1403.558, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1398.930, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1381.970, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1430.452, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1433.731, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1391.596, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1453.950, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1486.258, KL: 0.000\n",
      "Epoch: 36, batch: 0, loss: 1397.546, KL: 0.000\n",
      "\tEpoch: 36 (warmup phase), negative ELBO: 1470.937\n",
      "Epoch: 37, batch: 0, loss: 1391.750, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1433.740, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1434.405, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1425.369, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1377.944, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1397.080, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1380.208, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1409.438, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1425.184, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1473.512, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1473.787, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1394.877, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1434.510, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1393.415, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1429.008, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1398.457, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1437.181, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1389.735, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1385.933, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1451.862, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1380.547, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1418.905, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1385.574, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1474.168, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1452.621, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1463.379, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1386.730, KL: 0.000\n",
      "Epoch: 37, batch: 0, loss: 1459.001, KL: 0.000\n",
      "\tEpoch: 37 (warmup phase), negative ELBO: 1472.530\n",
      "Epoch: 38, batch: 0, loss: 1446.304, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1396.991, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1374.510, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1422.529, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1404.505, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1383.458, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1407.406, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1426.225, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1417.870, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1431.638, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1437.561, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1375.332, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1411.503, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1388.094, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1396.165, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1440.932, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1465.958, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1483.971, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1390.271, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1458.587, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1412.503, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1402.848, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1409.026, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1422.800, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1412.521, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1443.857, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1444.261, KL: 0.000\n",
      "Epoch: 38, batch: 0, loss: 1431.317, KL: 0.000\n",
      "\tEpoch: 38 (warmup phase), negative ELBO: 1471.813\n",
      "Epoch: 39, batch: 0, loss: 1413.614, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1424.429, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1397.464, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1401.523, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1390.324, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1395.029, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1405.007, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1460.164, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1463.284, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1350.480, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1449.029, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1415.424, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1379.805, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1438.767, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1454.079, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1480.013, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1405.749, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1495.037, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1421.415, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1387.828, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1415.860, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1383.143, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1419.781, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1404.593, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1414.403, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1400.118, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1456.884, KL: 0.000\n",
      "Epoch: 39, batch: 0, loss: 1379.252, KL: 0.000\n",
      "\tEpoch: 39 (warmup phase), negative ELBO: 1470.463\n",
      "Epoch: 40, batch: 0, loss: 1432.943, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1425.344, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1429.687, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1422.832, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1441.811, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1423.891, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1383.992, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1437.245, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1405.239, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1420.135, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1456.900, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1419.774, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1397.762, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1380.753, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1444.997, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1464.933, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1408.516, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1435.541, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1389.402, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1417.841, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1436.756, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1404.304, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1458.510, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1360.338, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1381.491, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1413.781, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1408.247, KL: 0.000\n",
      "Epoch: 40, batch: 0, loss: 1446.856, KL: 0.000\n",
      "\tEpoch: 40 (warmup phase), negative ELBO: 1472.216\n",
      "Epoch: 41, batch: 0, loss: 1418.402, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1426.962, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1346.498, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1457.419, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1383.874, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1435.517, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1425.738, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1381.162, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1408.541, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1437.263, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1422.356, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1393.530, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1447.144, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1409.842, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1413.568, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1437.223, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1446.365, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1410.976, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1374.832, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1408.642, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1439.626, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1427.772, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1425.494, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1421.465, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1397.817, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1426.463, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1479.113, KL: 0.000\n",
      "Epoch: 41, batch: 0, loss: 1444.724, KL: 0.000\n",
      "\tEpoch: 41 (warmup phase), negative ELBO: 1472.160\n",
      "Epoch: 42, batch: 0, loss: 1409.945, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1464.908, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1416.293, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1397.802, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1371.426, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1468.957, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1461.033, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1487.566, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1405.955, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1418.228, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1429.026, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1419.971, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1411.145, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1501.791, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1375.020, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1370.720, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1464.018, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1424.464, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1383.065, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1457.765, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1416.951, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1372.407, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1450.001, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1396.382, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1377.200, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1379.753, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1395.240, KL: 0.000\n",
      "Epoch: 42, batch: 0, loss: 1366.633, KL: 0.000\n",
      "\tEpoch: 42 (warmup phase), negative ELBO: 1470.136\n",
      "Epoch: 43, batch: 0, loss: 1454.946, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1417.372, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1389.728, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1423.890, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1472.992, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1422.537, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1432.733, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1377.881, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1382.796, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1428.288, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1410.645, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1486.861, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1426.031, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1495.698, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1444.796, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1377.004, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1423.492, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1405.952, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1413.916, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1420.133, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1434.887, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1385.227, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1388.029, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1393.041, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1366.306, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1393.956, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1445.369, KL: 0.000\n",
      "Epoch: 43, batch: 0, loss: 1408.385, KL: 0.000\n",
      "\tEpoch: 43 (warmup phase), negative ELBO: 1471.218\n",
      "Epoch: 44, batch: 0, loss: 1488.067, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1408.906, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1391.785, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1362.161, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1423.828, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1405.552, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1435.088, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1459.398, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1419.684, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1387.955, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1412.053, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1364.651, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1416.113, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1407.064, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1426.778, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1456.957, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1440.779, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1446.455, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1375.376, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1405.804, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1424.344, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1417.779, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1375.857, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1463.649, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1431.791, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1452.269, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1420.783, KL: 0.000\n",
      "Epoch: 44, batch: 0, loss: 1386.983, KL: 0.000\n",
      "\tEpoch: 44 (warmup phase), negative ELBO: 1470.663\n",
      "Epoch: 45, batch: 0, loss: 1426.452, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1430.809, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1436.583, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1452.205, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1387.936, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1404.576, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1388.211, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1439.055, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1415.423, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1421.195, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1459.333, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1407.183, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1396.500, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1399.160, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1409.770, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1420.076, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1436.576, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1414.032, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1415.320, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1435.778, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1413.137, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1391.062, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1396.573, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1440.659, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1453.363, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1427.974, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1401.475, KL: 0.000\n",
      "Epoch: 45, batch: 0, loss: 1388.685, KL: 0.000\n",
      "\tEpoch: 45 (warmup phase), negative ELBO: 1470.707\n",
      "Epoch: 46, batch: 0, loss: 1418.443, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1436.707, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1444.241, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1406.676, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1440.644, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1453.293, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1434.733, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1344.620, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1410.771, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1384.302, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1445.213, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1415.741, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1510.448, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1391.493, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1379.939, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1428.539, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1452.514, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1362.847, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1437.578, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1410.632, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1411.514, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1397.250, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1422.377, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1454.520, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1386.406, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1406.875, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1429.631, KL: 0.000\n",
      "Epoch: 46, batch: 0, loss: 1396.922, KL: 0.000\n",
      "\tEpoch: 46 (warmup phase), negative ELBO: 1470.921\n",
      "Epoch: 47, batch: 0, loss: 1401.834, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1415.991, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1440.810, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1425.294, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1456.161, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1449.707, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1484.495, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1392.372, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1425.177, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1394.157, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1382.300, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1404.090, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1412.088, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1385.547, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1398.312, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1454.678, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1424.016, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1379.608, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1371.474, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1426.655, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1419.340, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1407.814, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1426.125, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1421.053, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1427.453, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1455.757, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1419.765, KL: 0.000\n",
      "Epoch: 47, batch: 0, loss: 1449.824, KL: 0.000\n",
      "\tEpoch: 47 (warmup phase), negative ELBO: 1472.293\n",
      "Epoch: 48, batch: 0, loss: 1445.298, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1436.218, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1421.021, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1415.099, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1440.236, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1410.465, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1387.969, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1442.236, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1415.646, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1434.096, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1447.899, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1403.185, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1432.503, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1356.566, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1386.709, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1392.867, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1454.446, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1482.275, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1410.605, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1407.284, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1368.125, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1424.465, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1442.532, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1382.664, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1447.724, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1389.053, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1420.061, KL: 0.000\n",
      "Epoch: 48, batch: 0, loss: 1465.921, KL: 0.000\n",
      "\tEpoch: 48 (warmup phase), negative ELBO: 1472.710\n",
      "Epoch: 49, batch: 0, loss: 1396.334, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1420.387, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1430.042, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1432.443, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1431.958, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1438.284, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1378.041, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1397.497, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1432.006, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1396.536, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1425.251, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1427.451, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1391.977, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1416.167, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1451.132, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1400.609, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1401.016, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1415.949, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1391.173, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1448.864, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1414.010, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1412.367, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1415.899, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1411.498, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1458.206, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1419.181, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1470.068, KL: 0.000\n",
      "Epoch: 49, batch: 0, loss: 1375.587, KL: 0.000\n",
      "\tEpoch: 49 (warmup phase), negative ELBO: 1470.368\n",
      "Epoch: 50, batch: 0, loss: 1448.427, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1418.300, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1449.909, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1406.031, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1391.606, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1420.250, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1364.372, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1396.147, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1363.255, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1412.646, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1451.554, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1437.251, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1379.935, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1440.671, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1444.739, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1423.184, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1429.916, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1402.981, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1375.575, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1408.946, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1437.694, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1419.502, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1499.123, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1431.926, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1429.290, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1398.233, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1444.300, KL: 0.000\n",
      "Epoch: 50, batch: 0, loss: 1370.863, KL: 0.000\n",
      "\tEpoch: 50 (warmup phase), negative ELBO: 1470.245\n",
      "Epoch: 51, batch: 0, loss: 1437.481, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1423.356, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1363.455, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1407.699, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1424.725, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1395.125, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1416.429, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1411.695, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1408.181, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1441.958, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1442.417, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1440.733, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1412.339, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1406.490, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1418.905, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1382.958, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1385.147, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1472.445, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1385.877, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1439.806, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1426.077, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1438.270, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1433.398, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1454.535, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1441.756, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1404.301, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1393.658, KL: 0.000\n",
      "Epoch: 51, batch: 0, loss: 1426.010, KL: 0.000\n",
      "\tEpoch: 51 (warmup phase), negative ELBO: 1471.675\n",
      "Epoch: 52, batch: 0, loss: 1383.570, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1425.252, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1478.799, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1393.801, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1418.939, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1426.363, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1400.999, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1449.080, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1433.526, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1459.198, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1442.270, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1392.221, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1378.196, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1397.955, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1447.164, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1414.025, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1439.954, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1430.775, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1450.118, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1390.136, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1390.429, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1437.324, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1401.956, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1394.340, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1423.997, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1426.542, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1388.276, KL: 0.000\n",
      "Epoch: 52, batch: 0, loss: 1406.048, KL: 0.000\n",
      "\tEpoch: 52 (warmup phase), negative ELBO: 1471.158\n",
      "Epoch: 53, batch: 0, loss: 1369.749, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1453.198, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1421.679, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1452.016, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1399.998, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1449.889, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1399.686, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1382.081, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1419.194, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1381.628, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1468.846, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1445.213, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1402.418, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1477.914, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1431.850, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1403.840, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1374.864, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1411.442, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1409.893, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1434.822, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1409.783, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1405.958, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1442.401, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1459.460, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1437.068, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1379.349, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1374.945, KL: 0.000\n",
      "Epoch: 53, batch: 0, loss: 1459.456, KL: 0.000\n",
      "\tEpoch: 53 (warmup phase), negative ELBO: 1472.542\n",
      "Epoch: 54, batch: 0, loss: 1385.431, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1392.833, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1465.571, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1454.578, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1447.611, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1429.898, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1386.220, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1370.687, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1396.043, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1481.292, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1411.363, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1439.578, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1392.533, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1368.556, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1482.049, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1458.371, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1430.083, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1377.920, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1421.010, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1374.679, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1370.421, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1464.363, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1414.120, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1411.056, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1495.539, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1387.435, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1398.585, KL: 0.000\n",
      "Epoch: 54, batch: 0, loss: 1430.654, KL: 0.000\n",
      "\tEpoch: 54 (warmup phase), negative ELBO: 1471.796\n",
      "Epoch: 55, batch: 0, loss: 1400.241, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1341.709, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1389.808, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1385.790, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1352.101, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1424.152, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1396.572, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1434.958, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1463.448, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1422.346, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1422.725, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1451.175, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1409.830, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1433.178, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1466.542, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1390.811, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1404.289, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1504.252, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1439.353, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1454.729, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1409.907, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1431.146, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1428.742, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1375.828, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1433.264, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1428.154, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1427.358, KL: 0.000\n",
      "Epoch: 55, batch: 0, loss: 1382.036, KL: 0.000\n",
      "\tEpoch: 55 (warmup phase), negative ELBO: 1470.535\n",
      "Epoch: 56, batch: 0, loss: 1421.059, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1427.700, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1447.953, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1367.027, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1388.011, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1408.918, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1386.791, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1434.823, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1397.300, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1412.821, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1356.759, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1415.369, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1452.458, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1402.553, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1422.614, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1400.624, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1458.163, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1409.306, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1412.184, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1431.805, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1428.497, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1512.813, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1436.212, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1426.329, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1386.328, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1392.104, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1459.370, KL: 0.000\n",
      "Epoch: 56, batch: 0, loss: 1470.426, KL: 0.000\n",
      "\tEpoch: 56 (warmup phase), negative ELBO: 1472.827\n",
      "Epoch: 57, batch: 0, loss: 1422.919, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1452.568, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1383.883, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1428.160, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1378.245, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1452.148, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1410.158, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1392.443, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1424.382, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1376.124, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1395.435, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1425.692, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1383.171, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1510.955, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1396.123, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1489.628, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1393.314, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1362.432, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1474.037, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1442.381, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1389.243, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1420.536, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1405.761, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1451.076, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1411.006, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1411.366, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1445.300, KL: 0.000\n",
      "Epoch: 57, batch: 0, loss: 1361.782, KL: 0.000\n",
      "\tEpoch: 57 (warmup phase), negative ELBO: 1470.010\n",
      "Epoch: 58, batch: 0, loss: 1427.615, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1412.568, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1421.465, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1411.005, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1412.044, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1456.166, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1414.199, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1402.112, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1406.568, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1479.252, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1464.654, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1417.492, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1386.699, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1378.076, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1354.781, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1382.709, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1439.773, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1391.794, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1452.653, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1395.771, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1402.419, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1433.322, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1383.193, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1445.673, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1474.355, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1434.537, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1446.708, KL: 0.000\n",
      "Epoch: 58, batch: 0, loss: 1364.731, KL: 0.000\n",
      "\tEpoch: 58 (warmup phase), negative ELBO: 1470.086\n",
      "Epoch: 59, batch: 0, loss: 1399.163, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1473.430, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1398.464, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1436.167, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1401.712, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1377.828, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1437.884, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1418.092, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1459.213, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1404.543, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1389.291, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1418.369, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1404.730, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1390.223, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1387.977, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1472.934, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1414.240, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1473.398, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1455.956, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1414.758, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1411.907, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1371.852, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1372.909, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1437.442, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1449.819, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1413.132, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1409.458, KL: 0.000\n",
      "Epoch: 59, batch: 0, loss: 1473.762, KL: 0.000\n",
      "\tEpoch: 59 (warmup phase), negative ELBO: 1472.913\n",
      "Epoch: 60, batch: 0, loss: 1481.370, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1413.003, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1456.967, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1438.340, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1448.395, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1358.784, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1389.651, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1475.186, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1412.182, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1407.931, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1402.730, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1394.083, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1420.865, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1348.393, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1410.694, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1428.471, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1430.785, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1415.417, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1438.425, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1439.935, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1389.680, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1388.072, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1410.836, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1442.193, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1391.542, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1457.810, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1415.478, KL: 0.000\n",
      "Epoch: 60, batch: 0, loss: 1432.683, KL: 0.000\n",
      "\tEpoch: 60 (warmup phase), negative ELBO: 1471.848\n",
      "Epoch: 61, batch: 0, loss: 1423.268, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1376.484, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1376.503, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1402.740, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1476.347, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1433.182, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1419.210, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1452.180, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1367.404, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1424.035, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1478.658, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1410.560, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1432.259, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1477.512, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1453.444, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1366.388, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1412.416, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1405.826, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1457.245, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1396.621, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1376.942, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1399.481, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1389.576, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1445.338, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1438.280, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1424.844, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1410.367, KL: 0.000\n",
      "Epoch: 61, batch: 0, loss: 1366.375, KL: 0.000\n",
      "\tEpoch: 61 (warmup phase), negative ELBO: 1470.129\n",
      "Epoch: 62, batch: 0, loss: 1424.176, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1399.171, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1375.509, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1431.578, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1422.559, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1414.647, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1420.400, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1445.986, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1409.156, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1473.745, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1481.525, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1380.857, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1460.791, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1456.639, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1395.974, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1431.249, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1419.987, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1379.221, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1401.396, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1457.665, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1404.214, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1402.053, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1388.885, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1390.839, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1436.781, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1438.063, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1381.156, KL: 0.000\n",
      "Epoch: 62, batch: 0, loss: 1376.007, KL: 0.000\n",
      "\tEpoch: 62 (warmup phase), negative ELBO: 1470.379\n",
      "Epoch: 63, batch: 0, loss: 1419.206, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1437.590, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1393.562, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1432.655, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1468.794, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1417.586, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1475.883, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1425.040, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1425.023, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1368.571, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1425.568, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1382.812, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1443.808, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1397.115, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1464.073, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1398.701, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1423.281, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1416.729, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1392.124, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1429.363, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1393.657, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1425.549, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1378.984, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1427.674, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1410.305, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1400.301, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1415.469, KL: 0.000\n",
      "Epoch: 63, batch: 0, loss: 1491.995, KL: 0.000\n",
      "\tEpoch: 63 (warmup phase), negative ELBO: 1473.386\n",
      "Epoch: 64, batch: 0, loss: 1488.677, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1429.040, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1367.984, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1448.038, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1378.873, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1438.815, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1377.552, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1444.320, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1407.748, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1430.618, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1463.900, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1375.612, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1401.867, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1465.271, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1447.909, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1426.225, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1409.295, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1384.004, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1425.682, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1363.864, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1459.709, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1375.013, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1406.264, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1411.968, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1426.715, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1412.696, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1423.932, KL: 0.000\n",
      "Epoch: 64, batch: 0, loss: 1484.761, KL: 0.000\n",
      "\tEpoch: 64 (warmup phase), negative ELBO: 1473.198\n",
      "Epoch: 65, batch: 0, loss: 1421.431, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1424.630, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1427.723, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1430.104, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1462.892, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1415.181, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1423.370, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1407.647, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1407.494, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1391.534, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1364.962, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1393.464, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1382.957, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1402.360, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1437.478, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1366.716, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1426.241, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1393.338, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1443.448, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1431.035, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1495.586, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1404.974, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1419.474, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1397.397, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1431.681, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1434.787, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1493.568, KL: 0.000\n",
      "Epoch: 65, batch: 0, loss: 1351.830, KL: 0.000\n",
      "\tEpoch: 65 (warmup phase), negative ELBO: 1469.752\n",
      "Epoch: 66, batch: 0, loss: 1489.566, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1417.920, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1423.553, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1397.595, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1442.408, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1413.098, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1458.079, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1377.481, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1411.896, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1434.690, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1443.590, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1359.893, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1426.483, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1475.223, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1366.084, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1410.713, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1448.452, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1406.690, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1415.377, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1448.217, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1389.582, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1405.210, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1409.676, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1444.723, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1410.456, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1432.825, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1359.498, KL: 0.000\n",
      "Epoch: 66, batch: 0, loss: 1393.475, KL: 0.000\n",
      "\tEpoch: 66 (warmup phase), negative ELBO: 1470.832\n",
      "Epoch: 67, batch: 0, loss: 1420.208, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1416.581, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1396.863, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1445.434, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1409.751, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1409.368, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1404.876, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1390.173, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1396.811, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1389.532, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1451.296, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1473.692, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1427.287, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1363.224, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1446.399, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1410.028, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1452.425, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1441.233, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1435.601, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1437.351, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1397.877, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1429.783, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1432.615, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1395.562, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1392.823, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1425.137, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1406.731, KL: 0.000\n",
      "Epoch: 67, batch: 0, loss: 1461.209, KL: 0.000\n",
      "\tEpoch: 67 (warmup phase), negative ELBO: 1472.588\n",
      "Epoch: 68, batch: 0, loss: 1398.734, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1436.508, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1443.252, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1368.233, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1407.521, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1454.539, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1482.957, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1371.866, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1389.109, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1408.982, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1430.090, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1452.126, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1423.259, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1450.668, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1401.459, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1377.235, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1453.043, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1446.244, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1461.648, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1414.799, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1435.918, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1386.491, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1406.908, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1368.722, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1381.433, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1397.642, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1428.970, KL: 0.000\n",
      "Epoch: 68, batch: 0, loss: 1528.889, KL: 0.000\n",
      "\tEpoch: 68 (warmup phase), negative ELBO: 1474.342\n",
      "Epoch: 69, batch: 0, loss: 1417.553, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1358.635, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1388.200, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1430.330, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1387.320, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1537.879, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1464.874, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1437.288, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1375.770, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1430.170, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1427.383, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1452.161, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1411.678, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1389.020, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1459.657, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1426.208, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1456.676, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1389.264, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1379.138, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1418.303, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1435.347, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1439.791, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1348.423, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1455.654, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1400.790, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1394.854, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1390.364, KL: 0.000\n",
      "Epoch: 69, batch: 0, loss: 1447.634, KL: 0.000\n",
      "\tEpoch: 69 (warmup phase), negative ELBO: 1472.236\n",
      "Epoch: 70, batch: 0, loss: 1399.528, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1426.830, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1428.378, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1436.701, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1410.369, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1411.421, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1413.488, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1447.783, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1461.781, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1403.363, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1411.345, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1431.789, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1390.496, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1393.279, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1456.550, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1414.497, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1452.438, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1385.285, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1398.851, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1389.612, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1397.592, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1425.753, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1409.896, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1415.252, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1369.124, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1377.280, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1511.573, KL: 0.000\n",
      "Epoch: 70, batch: 0, loss: 1555.889, KL: 0.000\n",
      "\tEpoch: 70 (warmup phase), negative ELBO: 1475.042\n",
      "Epoch: 71, batch: 0, loss: 1422.139, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1437.884, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1395.566, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1393.358, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1446.845, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1473.728, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1403.052, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1368.518, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1415.702, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1471.999, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1385.501, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1376.726, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1441.898, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1447.083, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1385.478, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1450.771, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1423.356, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1440.374, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1406.945, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1392.772, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1404.660, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1399.343, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1420.920, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1439.115, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1408.298, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1422.806, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1459.056, KL: 0.000\n",
      "Epoch: 71, batch: 0, loss: 1343.756, KL: 0.000\n",
      "\tEpoch: 71 (warmup phase), negative ELBO: 1469.543\n",
      "Epoch: 72, batch: 0, loss: 1415.232, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1438.193, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1472.462, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1412.578, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1400.126, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1419.438, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1418.294, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1437.406, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1382.348, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1353.102, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1451.551, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1434.681, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1392.589, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1404.356, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1435.938, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1466.896, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1420.093, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1417.557, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1381.424, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1401.660, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1395.424, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1402.527, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1459.081, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1422.163, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1438.732, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1439.706, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1409.959, KL: 0.000\n",
      "Epoch: 72, batch: 0, loss: 1378.352, KL: 0.000\n",
      "\tEpoch: 72 (warmup phase), negative ELBO: 1470.440\n",
      "Epoch: 73, batch: 0, loss: 1380.130, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1399.767, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1404.032, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1397.396, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1358.317, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1420.382, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1413.634, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1424.591, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1406.207, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1454.891, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1402.536, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1443.955, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1459.346, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1456.451, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1382.981, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1467.758, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1464.305, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1456.328, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1465.236, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1379.775, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1359.720, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1438.089, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1443.037, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1380.401, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1363.722, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1471.017, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1403.707, KL: 0.000\n",
      "Epoch: 73, batch: 0, loss: 1464.380, KL: 0.000\n",
      "\tEpoch: 73 (warmup phase), negative ELBO: 1472.670\n",
      "Epoch: 74, batch: 0, loss: 1391.176, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1437.619, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1423.178, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1408.627, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1401.985, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1419.066, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1445.387, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1380.152, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1423.444, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1454.484, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1425.267, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1432.895, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1355.300, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1471.417, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1416.576, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1415.722, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1411.355, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1429.632, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1390.436, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1430.447, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1423.970, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1448.767, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1440.921, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1410.117, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1394.403, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1414.359, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1424.441, KL: 0.000\n",
      "Epoch: 74, batch: 0, loss: 1386.261, KL: 0.000\n",
      "\tEpoch: 74 (warmup phase), negative ELBO: 1470.645\n",
      "Epoch: 75, batch: 0, loss: 1406.808, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1409.589, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1476.127, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1403.712, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1421.950, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1383.308, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1435.007, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1411.273, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1403.790, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1501.573, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1418.341, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1409.035, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1386.757, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1377.696, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1491.332, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1436.887, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1402.162, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1410.649, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1432.202, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1383.027, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1446.535, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1441.477, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1455.373, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1380.677, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1388.336, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1416.010, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1392.773, KL: 0.000\n",
      "Epoch: 75, batch: 0, loss: 1382.054, KL: 0.000\n",
      "\tEpoch: 75 (warmup phase), negative ELBO: 1470.536\n",
      "Epoch: 76, batch: 0, loss: 1449.131, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1436.682, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1425.982, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1436.241, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1387.634, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1427.027, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1380.634, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1446.236, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1444.954, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1361.876, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1375.116, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1407.764, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1404.480, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1436.352, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1406.498, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1488.200, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1490.091, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1425.315, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1385.293, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1416.038, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1407.364, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1375.770, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1390.071, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1428.805, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1405.676, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1447.231, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1402.019, KL: 0.000\n",
      "Epoch: 76, batch: 0, loss: 1495.126, KL: 0.000\n",
      "\tEpoch: 76 (warmup phase), negative ELBO: 1473.467\n",
      "Epoch: 77, batch: 0, loss: 1350.402, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1470.499, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1389.705, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1441.699, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1396.153, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1436.760, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1428.032, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1430.609, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1385.371, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1480.290, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1403.690, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1418.780, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1425.244, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1422.384, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1419.416, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1382.714, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1446.399, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1438.167, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1527.479, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1447.229, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1387.641, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1396.500, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1388.371, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1393.620, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1388.264, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1398.238, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1422.634, KL: 0.000\n",
      "Epoch: 77, batch: 0, loss: 1402.436, KL: 0.000\n",
      "\tEpoch: 77 (warmup phase), negative ELBO: 1471.064\n",
      "Epoch: 78, batch: 0, loss: 1468.306, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1377.075, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1408.019, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1404.978, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1401.927, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1399.751, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1498.201, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1394.251, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1415.015, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1450.509, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1456.505, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1398.899, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1425.030, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1425.147, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1396.178, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1439.751, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1453.511, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1384.439, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1389.094, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1410.710, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1384.557, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1428.259, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1399.082, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1452.613, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1421.263, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1410.664, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1430.766, KL: 0.000\n",
      "Epoch: 78, batch: 0, loss: 1375.074, KL: 0.000\n",
      "\tEpoch: 78 (warmup phase), negative ELBO: 1470.355\n",
      "Epoch: 79, batch: 0, loss: 1408.478, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1402.275, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1438.462, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1411.697, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1439.173, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1385.906, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1474.695, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1389.315, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1366.384, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1415.800, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1395.826, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1449.682, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1364.805, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1447.956, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1422.746, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1431.585, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1370.917, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1456.686, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1407.123, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1438.051, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1382.830, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1483.654, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1449.062, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1411.983, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1416.451, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1420.633, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1435.723, KL: 0.000\n",
      "Epoch: 79, batch: 0, loss: 1397.080, KL: 0.000\n",
      "\tEpoch: 79 (warmup phase), negative ELBO: 1470.925\n",
      "Epoch: 80, batch: 0, loss: 1395.973, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1393.468, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1423.729, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1376.805, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1459.170, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1486.888, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1444.052, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1401.830, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1391.275, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1387.447, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1504.201, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1417.793, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1465.225, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1455.561, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1404.079, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1411.542, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1396.115, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1446.884, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1402.764, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1380.423, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1410.081, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1445.688, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1420.804, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1391.438, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1392.099, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1413.280, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1400.032, KL: 0.000\n",
      "Epoch: 80, batch: 0, loss: 1394.598, KL: 0.000\n",
      "\tEpoch: 80 (warmup phase), negative ELBO: 1470.861\n",
      "Epoch: 81, batch: 0, loss: 1418.685, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1448.865, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1442.737, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1393.955, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1401.358, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1433.103, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1518.534, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1402.482, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1440.739, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1385.511, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1398.089, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1392.163, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1415.521, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1378.949, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1432.184, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1406.066, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1391.011, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1382.714, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1438.408, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1449.093, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1442.732, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1374.436, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1442.086, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1412.216, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1442.996, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1440.462, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1394.442, KL: 0.000\n",
      "Epoch: 81, batch: 0, loss: 1391.609, KL: 0.000\n",
      "\tEpoch: 81 (warmup phase), negative ELBO: 1470.783\n",
      "Epoch: 82, batch: 0, loss: 1406.207, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1435.732, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1386.552, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1439.124, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1454.353, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1406.017, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1424.360, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1441.377, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1408.815, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1405.820, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1404.393, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1390.389, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1397.715, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1383.818, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1360.713, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1442.310, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1458.168, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1449.531, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1381.932, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1473.889, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1431.274, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1440.626, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1409.329, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1394.946, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1427.895, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1448.391, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1392.214, KL: 0.000\n",
      "Epoch: 82, batch: 0, loss: 1470.433, KL: 0.000\n",
      "\tEpoch: 82 (warmup phase), negative ELBO: 1472.827\n",
      "Epoch: 83, batch: 0, loss: 1412.986, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1437.565, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1452.343, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1399.506, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1427.110, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1413.685, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1357.966, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1385.288, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1410.956, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1406.691, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1410.627, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1387.619, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1398.201, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1424.541, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1452.667, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1401.232, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1388.376, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1409.717, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1457.915, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1395.614, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1441.632, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1423.938, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1408.979, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1466.576, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1447.185, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1489.768, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1404.101, KL: 0.000\n",
      "Epoch: 83, batch: 0, loss: 1414.130, KL: 0.000\n",
      "\tEpoch: 83 (warmup phase), negative ELBO: 1471.367\n",
      "Epoch: 84, batch: 0, loss: 1411.129, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1456.717, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1383.445, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1394.494, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1441.916, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1430.193, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1413.191, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1430.909, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1454.115, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1419.852, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1409.322, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1429.335, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1395.362, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1488.625, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1435.510, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1430.526, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1375.963, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1412.472, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1448.199, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1427.060, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1417.312, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1445.446, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1390.341, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1396.182, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1379.246, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1418.709, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1369.844, KL: 0.000\n",
      "Epoch: 84, batch: 0, loss: 1438.688, KL: 0.000\n",
      "\tEpoch: 84 (warmup phase), negative ELBO: 1472.004\n",
      "Epoch: 85, batch: 0, loss: 1438.108, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1429.510, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1410.798, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1474.617, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1463.481, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1405.595, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1428.519, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1438.266, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1435.582, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1403.949, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1376.817, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1384.525, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1409.708, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1398.074, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1422.742, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1402.147, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1407.168, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1397.169, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1404.222, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1397.400, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1406.063, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1420.707, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1475.057, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1392.451, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1463.957, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1418.419, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1385.929, KL: 0.000\n",
      "Epoch: 85, batch: 0, loss: 1486.810, KL: 0.000\n",
      "\tEpoch: 85 (warmup phase), negative ELBO: 1473.251\n",
      "Epoch: 86, batch: 0, loss: 1439.485, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1421.252, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1437.341, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1394.387, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1411.100, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1423.742, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1439.379, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1397.206, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1420.322, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1391.689, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1349.855, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1423.407, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1375.864, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1442.814, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1395.195, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1445.200, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1417.295, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1389.923, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1442.777, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1493.646, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1409.099, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1420.562, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1507.786, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1463.485, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1380.516, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1392.586, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1397.687, KL: 0.000\n",
      "Epoch: 86, batch: 0, loss: 1378.076, KL: 0.000\n",
      "\tEpoch: 86 (warmup phase), negative ELBO: 1470.432\n",
      "Epoch: 87, batch: 0, loss: 1467.378, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1416.795, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1412.803, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1405.418, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1450.363, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1404.301, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1442.263, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1408.429, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1396.372, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1410.772, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1433.911, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1372.450, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1468.760, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1462.791, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1421.297, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1393.399, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1398.217, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1501.150, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1416.095, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1359.431, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1412.271, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1403.213, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1410.741, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1389.483, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1404.440, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1415.523, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1448.645, KL: 0.000\n",
      "Epoch: 87, batch: 0, loss: 1367.691, KL: 0.000\n",
      "\tEpoch: 87 (warmup phase), negative ELBO: 1470.163\n",
      "Epoch: 88, batch: 0, loss: 1420.569, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1408.066, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1424.485, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1454.579, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1389.013, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1434.759, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1385.446, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1370.215, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1427.131, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1429.535, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1414.748, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1412.369, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1391.567, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1444.430, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1344.634, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1377.327, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1431.440, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1437.474, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1427.379, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1419.307, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1439.437, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1452.281, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1417.232, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1380.363, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1455.541, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1462.464, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1456.989, KL: 0.000\n",
      "Epoch: 88, batch: 0, loss: 1427.467, KL: 0.000\n",
      "\tEpoch: 88 (warmup phase), negative ELBO: 1471.713\n",
      "Epoch: 89, batch: 0, loss: 1432.852, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1389.806, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1455.130, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1355.162, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1410.493, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1406.232, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1419.759, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1430.701, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1417.865, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1400.099, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1462.736, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1438.285, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1400.742, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1412.642, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1411.657, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1467.059, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1512.482, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1379.032, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1393.975, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1364.712, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1449.565, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1394.452, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1486.255, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1390.493, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1412.050, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1392.807, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1417.438, KL: 0.000\n",
      "Epoch: 89, batch: 0, loss: 1441.798, KL: 0.000\n",
      "\tEpoch: 89 (warmup phase), negative ELBO: 1472.084\n",
      "Epoch: 90, batch: 0, loss: 1426.371, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1383.160, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1403.214, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1429.988, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1389.810, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1391.639, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1355.658, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1443.130, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1445.788, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1381.802, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1437.608, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1417.195, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1417.507, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1383.623, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1452.202, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1408.448, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1390.487, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1429.416, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1439.435, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1420.813, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1473.523, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1435.590, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1454.370, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1382.784, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1430.309, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1427.397, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1435.283, KL: 0.000\n",
      "Epoch: 90, batch: 0, loss: 1501.569, KL: 0.000\n",
      "\tEpoch: 90 (warmup phase), negative ELBO: 1473.634\n",
      "Epoch: 91, batch: 0, loss: 1366.721, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1435.236, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1347.939, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1421.563, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1415.612, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1448.817, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1425.839, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1518.884, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1454.727, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1369.042, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1420.851, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1485.189, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1440.456, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1417.263, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1431.087, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1416.139, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1411.801, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1473.148, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1375.802, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1435.087, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1371.277, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1426.811, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1410.629, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1365.993, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1464.474, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1418.206, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1367.979, KL: 0.000\n",
      "Epoch: 91, batch: 0, loss: 1334.837, KL: 0.000\n",
      "\tEpoch: 91 (warmup phase), negative ELBO: 1469.311\n",
      "Epoch: 92, batch: 0, loss: 1404.733, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1441.079, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1428.554, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1462.040, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1419.183, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1371.732, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1416.740, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1442.735, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1376.664, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1441.142, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1437.652, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1396.922, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1421.543, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1388.875, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1401.890, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1440.272, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1396.232, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1420.462, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1410.990, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1431.777, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1432.793, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1448.823, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1432.835, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1400.686, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1455.651, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1403.366, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1380.845, KL: 0.000\n",
      "Epoch: 92, batch: 0, loss: 1436.021, KL: 0.000\n",
      "\tEpoch: 92 (warmup phase), negative ELBO: 1471.935\n",
      "Epoch: 93, batch: 0, loss: 1425.114, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1423.075, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1428.945, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1407.733, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1425.099, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1391.670, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1399.739, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1379.477, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1413.813, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1375.062, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1464.515, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1458.257, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1400.112, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1435.781, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1383.323, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1386.279, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1412.652, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1469.934, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1444.672, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1447.198, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1405.651, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1430.841, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1360.720, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1423.424, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1481.349, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1444.424, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1396.781, KL: 0.000\n",
      "Epoch: 93, batch: 0, loss: 1404.597, KL: 0.000\n",
      "\tEpoch: 93 (warmup phase), negative ELBO: 1471.120\n",
      "Epoch: 94, batch: 0, loss: 1458.410, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1396.860, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1404.200, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1379.459, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1423.169, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1392.560, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1415.905, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1425.667, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1380.016, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1416.834, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1414.880, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1404.712, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1476.325, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1435.793, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1403.699, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1452.441, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1437.119, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1412.900, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1433.470, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1430.276, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1415.971, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1424.517, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1449.441, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1396.190, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1362.511, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1446.779, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1423.646, KL: 0.000\n",
      "Epoch: 94, batch: 0, loss: 1410.912, KL: 0.000\n",
      "\tEpoch: 94 (warmup phase), negative ELBO: 1471.284\n",
      "Epoch: 95, batch: 0, loss: 1378.935, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1463.056, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1481.658, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1376.001, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1406.264, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1458.006, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1372.783, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1432.179, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1431.568, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1463.271, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1425.016, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1376.379, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1457.132, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1364.579, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1408.786, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1379.433, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1384.474, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1373.833, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1452.274, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1419.267, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1382.406, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1422.797, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1435.055, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1404.170, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1402.087, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1466.054, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1448.508, KL: 0.000\n",
      "Epoch: 95, batch: 0, loss: 1570.168, KL: 0.000\n",
      "\tEpoch: 95 (warmup phase), negative ELBO: 1475.413\n",
      "Epoch: 96, batch: 0, loss: 1441.316, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1427.718, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1475.771, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1433.259, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1460.074, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1363.250, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1405.907, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1437.959, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1436.982, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1419.674, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1397.592, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1388.584, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1386.371, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1422.946, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1390.253, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1407.754, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1404.063, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1442.958, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1416.101, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1428.385, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1390.762, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1397.740, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1454.509, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1414.878, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1460.008, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1423.531, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1390.927, KL: 0.000\n",
      "Epoch: 96, batch: 0, loss: 1392.500, KL: 0.000\n",
      "\tEpoch: 96 (warmup phase), negative ELBO: 1470.806\n",
      "Epoch: 97, batch: 0, loss: 1397.031, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1385.768, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1457.691, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1361.357, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1427.385, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1387.301, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1408.625, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1414.162, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1391.167, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1413.273, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1477.270, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1450.914, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1465.095, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1378.361, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1386.564, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1416.724, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1410.276, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1435.496, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1422.901, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1375.483, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1488.623, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1453.531, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1419.739, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1423.209, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1411.446, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1423.660, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1435.898, KL: 0.000\n",
      "Epoch: 97, batch: 0, loss: 1393.574, KL: 0.000\n",
      "\tEpoch: 97 (warmup phase), negative ELBO: 1470.834\n",
      "Epoch: 98, batch: 0, loss: 1404.438, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1449.606, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1435.163, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1405.100, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1437.266, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1400.712, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1402.292, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1431.993, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1447.926, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1398.645, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1400.482, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1475.740, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1474.478, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1399.824, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1416.658, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1350.238, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1400.331, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1340.407, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1432.769, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1459.040, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1427.944, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1424.569, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1410.250, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1363.805, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1465.482, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1443.437, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1386.655, KL: 0.000\n",
      "Epoch: 98, batch: 0, loss: 1505.896, KL: 0.000\n",
      "\tEpoch: 98 (warmup phase), negative ELBO: 1473.746\n",
      "Epoch: 99, batch: 0, loss: 1403.567, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1473.414, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1409.485, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1418.603, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1387.057, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1458.425, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1379.681, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1412.660, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1417.980, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1404.960, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1447.430, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1415.205, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1445.754, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1376.657, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1420.001, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1398.598, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1418.826, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1432.264, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1410.051, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1375.164, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1403.237, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1432.323, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1470.289, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1439.207, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1413.943, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1426.916, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1434.808, KL: 0.000\n",
      "Epoch: 99, batch: 0, loss: 1368.386, KL: 0.000\n",
      "\tEpoch: 99 (warmup phase), negative ELBO: 1470.181\n",
      "Epoch: 100, batch: 0, loss: 1464.548, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1367.768, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1411.968, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1366.509, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1434.111, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1457.055, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1402.536, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1371.390, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1374.980, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1462.186, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1387.099, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1440.400, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1403.761, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1366.530, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1467.139, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1413.136, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1415.480, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1432.296, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1444.800, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1392.995, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1469.405, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1468.722, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1400.106, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1416.163, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1431.251, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1440.697, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1416.585, KL: 0.000\n",
      "Epoch: 100, batch: 0, loss: 1391.345, KL: 0.000\n",
      "\tEpoch: 100 (warmup phase), negative ELBO: 1470.776\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Experiment' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20744\\60825566.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20744\\609630526.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;31m# warmup checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0msavepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvae_save_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_warmup\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Experiment' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "experiment.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
